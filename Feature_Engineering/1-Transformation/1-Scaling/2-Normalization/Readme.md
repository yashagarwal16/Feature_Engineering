# ğŸ“ Feature Scaling: Normalization in Machine Learning

## ğŸ” What is Normalization?

**Normalization** is a data preprocessing technique used to **rescale feature values** so they are on a similar scale.

This is important because many machine learning algorithms perform better or converge faster when input features are scaled.

---

## âš™ï¸ 1. Min-Max Normalization

### âœ… Formula:

```
x_scaled = (x - min(x)) / (max(x) - min(x))
```

- Scales features to a **range [0, 1]**
- Preserves relationships between values
- âš ï¸ **Sensitive to outliers**

### ğŸ§ª Python Example (Using scikit-learn):

```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data)
```

---

## âš™ï¸ 2. Standardization (Z-score Scaling)

### âœ… Formula:

```
z = (x - mean) / standard_deviation
```

- Centers features around **0**
- Scales to **unit variance (1)**
- Suitable when data is **normally distributed**

### ğŸ§ª Python Example:

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)
```

---

## âš™ï¸ 3. MaxAbs Scaling

### âœ… Formula:

```
x_scaled = x / max(abs(x))
```

- Scales to range **[-1, 1]**
- Good for **sparse data** (many zeros)
- Keeps sign of data

### ğŸ§ª Python Example:

```python
from sklearn.preprocessing import MaxAbsScaler

scaler = MaxAbsScaler()
scaled_data = scaler.fit_transform(data)
```

---

## âš™ï¸ 4. Robust Scaling

### âœ… Formula:

```
x_scaled = (x - median) / IQR
```

- Uses **median** and **interquartile range**
- **Robust to outliers**

### ğŸ§ª Python Example:

```python
from sklearn.preprocessing import RobustScaler

scaler = RobustScaler()
scaled_data = scaler.fit_transform(data)
```

---

## ğŸ§­ When to Use Which?

| Method             | Best Use Case                                                              |
|--------------------|----------------------------------------------------------------------------|
| **Min-Max**        | When you need data in a **fixed range [0, 1]**, such as for neural networks |
| **StandardScaler** | When data is **normally distributed**                                      |
| **MaxAbsScaler**   | When data is **sparse**, e.g., text data                                   |
| **RobustScaler**   | When your data has **many outliers**                                       |

---

## ğŸ§  Summary

- Normalization ensures fair comparison between features.
- Choosing the right scaling method can **significantly improve model performance**.
- Use `scikit-learn`â€™s scalers to implement easily in Python.
```